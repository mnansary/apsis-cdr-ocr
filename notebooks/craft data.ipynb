{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2acde760",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from glob import glob\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()\n",
    "import json\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from coreLib.segment import *\n",
    "\n",
    "\n",
    "template_path=\"image.png\"\n",
    "tem=cv2.imread(template_path)\n",
    "gmap=gaussian_heatmap(distanceRatio=1.5)\n",
    "f = open('tem.json')\n",
    "temdata = json.load(f)\n",
    "loc_dict={}\n",
    "for _d in temdata['image.png926838'][\"regions\"]:\n",
    "    xmin=_d['shape_attributes']['x']\n",
    "    ymin=_d['shape_attributes']['y']\n",
    "    xmax=_d['shape_attributes']['width']+xmin\n",
    "    ymax=_d['shape_attributes']['height']+ymin\n",
    "    field=_d['region_attributes']['field']\n",
    "    loc_dict[field]=[xmin,ymin,xmax,ymax]\n",
    "    \n",
    "g1=[28,883,28+267,883+177]\n",
    "g2=[632,886,632+257,886+194]\n",
    "max_words=3\n",
    "max_wlen=5\n",
    "age_boxes=[]\n",
    "mb_boxes=[]\n",
    "for k,v in loc_dict.items():\n",
    "    if \"a\" in k:\n",
    "        age_boxes.append(v)\n",
    "    if \"m\" in k:\n",
    "        mb_boxes.append(v)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00338b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir=\"//home/apsisdev/ansary/DATASETS/APSIS/CDR/datasets/craft/\"\n",
    "img_dir=os.path.join(save_dir,\"images\")\n",
    "heat_dir=os.path.join(save_dir,\"heats\")\n",
    "link_dir=os.path.join(save_dir,\"links\")\n",
    "\n",
    "bn_gdir=\"/home/apsisdev/ansary/DATASETS/APSIS/Recognition/source/bangla/\"\n",
    "bn_df=pd.read_csv(os.path.join(bn_gdir,\"graphemes.csv\"))\n",
    "bn_df.filename=bn_df.filename.progress_apply(lambda x:os.path.join(bn_gdir,\"graphemes\",f\"{x}.bmp\"))\n",
    "bn_comps=bn_df.label.unique()\n",
    "en_gdir=\"/home/apsisdev/ansary/DATASETS/APSIS/Recognition/source/english/\"\n",
    "en_df=pd.read_csv(os.path.join(en_gdir,\"graphemes.csv\"))\n",
    "en_df.filename=en_df.filename.progress_apply(lambda x:os.path.join(en_gdir,\"graphemes\",f\"{x}.bmp\"))\n",
    "en_comps=en_df.label.unique()\n",
    "\n",
    "bn_ndf=pd.read_csv(\"/home/apsisdev/ansary/DATASETS/BnNums/data.csv\")\n",
    "en_ndf=pd.read_csv(\"/home/apsisdev/ansary/DATASETS/EnNums/data.csv\")\n",
    "\n",
    "backs=\"/home/apsisdev/ansary/DATASETS/APSIS/Recognition/source/common/background/\"\n",
    "backs=[_path for _path in tqdm(glob(os.path.join(backs,\"*.*\")))]\n",
    "backgen= backgroundGenerator(backs)\n",
    "back=next(backgen)\n",
    "plt.imshow(back)\n",
    "plt.show()\n",
    "print(len(bn_df))\n",
    "print(len(en_df))\n",
    "print(len(bn_ndf))\n",
    "print(len(en_ndf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b324c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_single(dim=(512,512)):\n",
    "    gdf=random.choice([0,0,0,1])\n",
    "    if gdf==1:\n",
    "        gdf=en_df\n",
    "        gcomps=en_comps\n",
    "    else:\n",
    "        gdf=bn_df\n",
    "        gcomps=bn_comps\n",
    "    img,mask,labels=placeName(2,gdf,gcomps,tem,loc_dict,max_wlen=5)\n",
    "    heat_mask1,link_mask1=lineTextPage(mask,labels,gmap)\n",
    "    # garbage\n",
    "    #img=placeGarbage(img,g1,gdf,gcomps)\n",
    "    #img=placeGarbage(img,g2,gdf,gcomps)\n",
    "    \n",
    "    # numbers\n",
    "    ndf=random.choice([bn_ndf,en_ndf])\n",
    "    img=placeNumbers(ndf,mb_boxes,img)\n",
    "    heat_mask2,link_mask2=lineTextBox(mask,mb_boxes,gmap)\n",
    "    ndf=random.choice([bn_ndf,en_ndf])\n",
    "    img=placeNumbers(ndf,age_boxes,img)\n",
    "    heat_mask3,link_mask3=lineTextBox(mask,age_boxes,gmap)\n",
    "    heat=heat_mask1+heat_mask2+heat_mask3\n",
    "    link=link_mask1+link_mask2+link_mask3\n",
    "    img,heat,link,mask=augment(img,heat,link)\n",
    "    back=next(backgen)\n",
    "    h,w,d=img.shape\n",
    "    back=cv2.resize(back,(w,h))\n",
    "    back[mask>0]=img[mask>0]\n",
    "    back=padDetectionImage(back)\n",
    "    heat=padDetectionImage(heat,gray=True,pad_value=0)\n",
    "    link=padDetectionImage(link,gray=True,pad_value=0)\n",
    "    \n",
    "    back=cv2.resize(back,(dim))\n",
    "    heat=cv2.resize(heat,(dim),fx=0,fy=0,interpolation = cv2.INTER_NEAREST)\n",
    "    link=cv2.resize(link,(dim),fx=0,fy=0,interpolation = cv2.INTER_NEAREST)\n",
    "    return back,heat,link\n",
    "\n",
    "img,heat,link=create_single()\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "plt.imshow(heat)\n",
    "plt.show()\n",
    "plt.imshow(link)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069a59f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(10000)):\n",
    "    try:\n",
    "        img,heat,link=create_single()\n",
    "        cv2.imwrite(os.path.join(img_dir,f\"{i}.png\"),img)\n",
    "        cv2.imwrite(os.path.join(heat_dir,f\"{i}.png\"),heat)\n",
    "        cv2.imwrite(os.path.join(link_dir,f\"{i}.png\"),link)\n",
    "    except Exception as e:\n",
    "        pass    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7ab156",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf \n",
    "from tqdm import tqdm\n",
    "from glob import glob \n",
    "import cv2 \n",
    "# ---------------------------------------------------------\n",
    "# globals\n",
    "# ---------------------------------------------------------\n",
    "# number of images to store in a tfrecord\n",
    "DATA_NUM  = 128\n",
    "#---------------------------------------------------------------\n",
    "def _bytes_feature(value):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def to_tfrecord(image_paths,save_dir,r_num):\n",
    "    '''\t            \n",
    "      Creates tfrecords from Provided Image Paths\t        \n",
    "      args:\t        \n",
    "        image_paths     :   specific number of image paths\t       \n",
    "        save_dir        :   location to save the tfrecords\t           \n",
    "        r_num           :   record number\t\n",
    "    '''\n",
    "    # record name\n",
    "    tfrecord_name='{}.tfrecord'.format(r_num)\n",
    "    # path\n",
    "    tfrecord_path=os.path.join(save_dir,tfrecord_name)\n",
    "    with tf.io.TFRecordWriter(tfrecord_path) as writer:    \n",
    "        for image_path in image_paths:\n",
    "            \n",
    "            char_path=str(image_path).replace('images','heats')\n",
    "            word_path=str(image_path).replace('images','links')\n",
    "            #image\n",
    "            with(open(image_path,'rb')) as fid:\n",
    "                image_bytes=fid.read()\n",
    "            # char\n",
    "            with(open(char_path,'rb')) as fid:\n",
    "                char_bytes=fid.read()\n",
    "            \n",
    "            # word\n",
    "            with(open(word_path,'rb')) as fid:\n",
    "                word_bytes=fid.read()\n",
    "            \n",
    "            \n",
    "            \n",
    "            data ={ 'image':_bytes_feature(image_bytes),\n",
    "                    'heatmap':_bytes_feature(char_bytes),\n",
    "                    'linkmap':_bytes_feature(word_bytes)\n",
    "            }\n",
    "            \n",
    "            \n",
    "            \n",
    "            # write\n",
    "            features=tf.train.Features(feature=data)\n",
    "            example= tf.train.Example(features=features)\n",
    "            serialized=example.SerializeToString()\n",
    "            writer.write(serialized)\n",
    "\n",
    "\n",
    "def genTFRecords(_paths,mode_dir):\n",
    "    '''\t        \n",
    "        tf record wrapper\n",
    "        args:\t        \n",
    "            _paths    :   all image paths for a mode\t        \n",
    "            mode_dir  :   location to save the tfrecords\t    \n",
    "    '''\n",
    "    for i in tqdm(range(0,len(_paths),DATA_NUM)):\n",
    "        # paths\n",
    "        image_paths= _paths[i:i+DATA_NUM]\n",
    "        # record num\n",
    "        r_num=i // DATA_NUM\n",
    "        # create tfrecord\n",
    "        to_tfrecord(image_paths,mode_dir,r_num)    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb4a785",
   "metadata": {},
   "outputs": [],
   "source": [
    "_paths=[img_path for img_path in tqdm(glob(os.path.join(img_dir,\"*.*\")))]\n",
    "save_path=os.path.join(save_dir,\"tfrecords\")\n",
    "genTFRecords(_paths,save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3b87ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "83cb0fe33a0a67f9f877ffb776c4b7cce63e124f7ba47fe6878fb868bcc96314"
  },
  "kernelspec": {
   "display_name": "bangla",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

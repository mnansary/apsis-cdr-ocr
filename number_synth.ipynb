{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1758254a",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_dir=\"/home/apsisdev/ansary/DATASETS/EnNums/\"\n",
    "bn_dir=\"/home/apsisdev/ansary/DATASETS/BnNums/\"\n",
    "save_dir=\"/home/apsisdev/ansary/DATASETS/APSIS/CDR/datasets/numbers/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c82a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot  as plt\n",
    "tqdm.pandas()\n",
    "import random\n",
    "from coreLib.processing import correctPadding\n",
    "from coreLib.utils import create_dir\n",
    "en_vocab=[\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\"]\n",
    "bn_vocab=['০', '১', '২', '৩', '৪', '৫', '৬', '৭', '৮', '৯']\n",
    "\n",
    "def random_exec(poplutation=[0,1],weights=[0.5,0.5],match=0):\n",
    "    return random.choices(population=poplutation,weights=weights,k=1)[0]==match\n",
    "\n",
    "def get_df_dict(_dir,vocab):\n",
    "    csv=os.path.join(_dir,\"data.csv\")\n",
    "    df=pd.read_csv(csv)\n",
    "    df.label=df.label.progress_apply(lambda x:str(x))\n",
    "    df_dict={}\n",
    "    for v in vocab:\n",
    "        vdf=df.loc[df.label==v]\n",
    "        vdf.reset_index(inplace=True,drop=True)\n",
    "        df_dict[v]=vdf\n",
    "    return df_dict\n",
    "\n",
    "def get_rand_img_path(df_dict,comp):\n",
    "    df=df_dict[comp]\n",
    "    idx=random.randint(0,len(df)-1)\n",
    "    return df.iloc[idx,0]\n",
    "\n",
    "def padAllAround(img,pad_dim,pad_val,pad_single=None):\n",
    "    '''\n",
    "        pads all around the image\n",
    "    '''\n",
    "    if pad_single is None:\n",
    "        h,w=img.shape\n",
    "        # pads\n",
    "        left_pad =np.ones((h,pad_dim))*pad_val\n",
    "        right_pad=np.ones((h,pad_dim))*pad_val\n",
    "        # pad\n",
    "        img =np.concatenate([left_pad,img,right_pad],axis=1)\n",
    "        # shape\n",
    "        h,w=img.shape\n",
    "        top_pad =np.ones((pad_dim,w))*pad_val\n",
    "        bot_pad=np.ones((pad_dim,w))*pad_val\n",
    "        # pad\n",
    "        img =np.concatenate([top_pad,img,bot_pad],axis=0)\n",
    "    elif pad_single==\"tb\":\n",
    "        # shape\n",
    "        h,w=img.shape\n",
    "        top_pad =np.ones((pad_dim,w))*pad_val\n",
    "        bot_pad=np.ones((pad_dim,w))*pad_val\n",
    "        # pad\n",
    "        img =np.concatenate([top_pad,img,bot_pad],axis=0)\n",
    "    else:\n",
    "        h,w=img.shape\n",
    "        # pads\n",
    "        left_pad =np.ones((h,pad_dim))*pad_val\n",
    "        right_pad=np.ones((h,pad_dim))*pad_val\n",
    "        # pad\n",
    "        img =np.concatenate([left_pad,img,right_pad],axis=1)\n",
    "    return img\n",
    "\n",
    "def create_labeled_box(num_box):\n",
    "    labeled=[]\n",
    "    bsize=random.randint(64,96)\n",
    "    side=random.randint(0,10)\n",
    "    thickness=random.randint(2,8)\n",
    "    pad=random.randint(2,5)\n",
    "    for i in range(num_box):\n",
    "        iden=i+2\n",
    "        box=np.ones((bsize,bsize))*iden\n",
    "        box=padAllAround(box,thickness,0)\n",
    "        box=padAllAround(box,pad,1)\n",
    "        labeled.append(box)\n",
    "    box=np.concatenate(labeled,axis=-1)\n",
    "    if random_exec():\n",
    "        box=padAllAround(box,side,1,pad_single=\"tb\")\n",
    "    return  box.astype(\"uint8\")\n",
    "\n",
    "def randColor(col=True):\n",
    "    '''\n",
    "        generates random color\n",
    "    '''\n",
    "    if col:\n",
    "        return (random.randint(0,255),random.randint(0,255),random.randint(0,255))\n",
    "    else:\n",
    "        d=random.randint(0,64)\n",
    "        return (d,d,d)\n",
    "\n",
    "def noisy(image):\n",
    "    row,col,ch= image.shape\n",
    "    mean = 0\n",
    "    var = random.randint(1,2)/10\n",
    "    sigma = var**0.5\n",
    "    gauss = np.random.normal(mean,sigma,(row,col,ch))\n",
    "    gauss = gauss.reshape(row,col,ch)\n",
    "    noisy = image + gauss\n",
    "    \n",
    "    return noisy\n",
    "\n",
    "\n",
    "def create_number_image(df_dict,data):\n",
    "    cimgs=[cv2.imread(get_rand_img_path(df_dict,c)) for c in data]\n",
    "    box_map=create_labeled_box(len(data))\n",
    "    midxs=sorted(np.unique(box_map))[2:]\n",
    "\n",
    "    h,w=box_map.shape\n",
    "    mask=np.zeros_like(box_map) \n",
    "    img=np.ones((h,w,3))*255\n",
    "    \n",
    "    back=np.copy(img)\n",
    "    back[box_map==0]=randColor()\n",
    "    back=cv2.GaussianBlur(back,(5,5),0) \n",
    "    img=noisy(img)\n",
    "    back=noisy(back)\n",
    "    \n",
    "    for cimg,midx in zip(cimgs,midxs):\n",
    "        # placement\n",
    "        idx = np.where(box_map==midx)                \n",
    "        x_min,x_max = np.min(idx[1]), np.max(idx[1])\n",
    "        y_min,y_max=0,h\n",
    "        cw=x_max-x_min\n",
    "        # fix\n",
    "        cimg=cv2.resize(cimg,(cw,h))\n",
    "        img[y_min:y_max,x_min:x_max]=cimg\n",
    "\n",
    "    img[box_map==0]=back[box_map==0]\n",
    "    img=img.astype(\"uint8\")\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7540a8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data=\"01786044716\"\n",
    "# df_dict=get_df_dict(en_dir,en_vocab)\n",
    "# plt.imshow(create_number_image(df_dict,data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b71ca7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples=1000000\n",
    "_vocab=en_vocab\n",
    "_dir=en_dir\n",
    "lang_dir=create_dir(save_dir,\"english\")\n",
    "img_dir=create_dir(lang_dir,\"images\")\n",
    "data_csv=os.path.join(lang_dir,\"data.csv\")\n",
    "df_dict=get_df_dict(_dir,_vocab)\n",
    "words=[]\n",
    "labels=[]\n",
    "masks=[]\n",
    "filepaths=[]\n",
    "max_len=15\n",
    "\n",
    "for i in tqdm(range(num_samples)):\n",
    "    try:\n",
    "        if random_exec(weights=[0.65,0.35]):\n",
    "            dlen=11\n",
    "        else:\n",
    "            if random_exec(weights=[0.65,0.35]):\n",
    "                dlen=2\n",
    "            else:\n",
    "                dlen=random.randint(3,10)\n",
    "        label=\"\".join([random.choice(_vocab) for _ in range(dlen)])\n",
    "        #d-w\n",
    "        words.append(label)\n",
    "\n",
    "        img=create_number_image(df_dict,label)\n",
    "        img,mask=correctPadding(img,dim=(64,512),ptype=\"left\")\n",
    "        #d-m\n",
    "        masks.append(mask)\n",
    "        # d-f\n",
    "        filepath=os.path.join(img_dir,f\"{i}.png\")\n",
    "        cv2.imwrite(filepath,img)\n",
    "        filepaths.append(filepath)\n",
    "        # d-l\n",
    "        label=[_vocab.index(c)+1 for c in label]\n",
    "        for _ in range(max_len-len(label)):\n",
    "            label.append(0)\n",
    "        labels.append(label)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "\n",
    "df=pd.DataFrame({\"filepath\":filepaths,\"label\":labels,\"word\":words,\"mask\":masks})\n",
    "df.to_csv(data_csv,index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42cdf8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples=1000000\n",
    "_vocab=bn_vocab\n",
    "_dir=bn_dir\n",
    "lang_dir=create_dir(save_dir,\"bangla\")\n",
    "img_dir=create_dir(lang_dir,\"images\")\n",
    "data_csv=os.path.join(lang_dir,\"data.csv\")\n",
    "df_dict=get_df_dict(_dir,_vocab)\n",
    "words=[]\n",
    "labels=[]\n",
    "masks=[]\n",
    "filepaths=[]\n",
    "max_len=15\n",
    "\n",
    "for i in tqdm(range(num_samples)):\n",
    "    try:\n",
    "        if random_exec(weights=[0.65,0.35]):\n",
    "            dlen=11\n",
    "        else:\n",
    "            if random_exec(weights=[0.65,0.35]):\n",
    "                dlen=2\n",
    "            else:\n",
    "                dlen=random.randint(3,10)\n",
    "        label=\"\".join([random.choice(_vocab) for _ in range(dlen)])\n",
    "        #d-w\n",
    "        words.append(label)\n",
    "\n",
    "        img=create_number_image(df_dict,label)\n",
    "        img,mask=correctPadding(img,dim=(64,512),ptype=\"left\")\n",
    "        #d-m\n",
    "        masks.append(mask)\n",
    "        # d-f\n",
    "        filepath=os.path.join(img_dir,f\"{i}.png\")\n",
    "        cv2.imwrite(filepath,img)\n",
    "        filepaths.append(filepath)\n",
    "        # d-l\n",
    "        label=[_vocab.index(c)+1 for c in label]\n",
    "        for _ in range(max_len-len(label)):\n",
    "            label.append(0)\n",
    "        labels.append(label)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "\n",
    "df=pd.DataFrame({\"filepath\":filepaths,\"label\":labels,\"word\":words,\"mask\":masks})\n",
    "df.to_csv(data_csv,index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081f38c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os \n",
    "import json\n",
    "import math\n",
    "import pandas as pd \n",
    "import tensorflow as tf\n",
    "import numpy as np \n",
    "from ast import literal_eval\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()\n",
    "#---------------------------------------------------------------\n",
    "# data functions\n",
    "#---------------------------------------------------------------\n",
    "cols=[\"filepath\",\"label\",\"word\",\"mask\"]\n",
    "eval_cols=[\"label\"]\n",
    "    \n",
    "# feature fuctions\n",
    "def _bytes_feature(value):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "def _int64_list_feature(value):\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=value))\n",
    "\n",
    "\n",
    "def toTfrecord(df,rnum,rec_path):\n",
    "    '''\n",
    "        args:\n",
    "            df      :   the dataframe that contains the information to store\n",
    "            rnum    :   record number\n",
    "            rec_path:   save_path\n",
    "            mask_dim:   the dimension of the mask\n",
    "    '''\n",
    "    tfrecord_name=f'{rnum}.tfrecord'\n",
    "    tfrecord_path=os.path.join(rec_path,tfrecord_name) \n",
    "    with tf.io.TFRecordWriter(tfrecord_path) as writer:    \n",
    "        \n",
    "        for idx in range(len(df)):\n",
    "            # base\n",
    "            img_path=df.iloc[idx,0]\n",
    "            # img\n",
    "            with(open(img_path,'rb')) as fid:\n",
    "                image_png_bytes=fid.read()\n",
    "            # feature desc\n",
    "            data ={ 'image':_bytes_feature(image_png_bytes)}\n",
    "\n",
    "            for cidx,col in enumerate(cols):\n",
    "                if col in eval_cols:\n",
    "                    data[col]=_int64_list_feature(df.iloc[idx,cidx]) \n",
    "\n",
    "            \n",
    "            features=tf.train.Features(feature=data)\n",
    "            example= tf.train.Example(features=features)\n",
    "            serialized=example.SerializeToString()\n",
    "            writer.write(serialized)  \n",
    "\n",
    "def createRecords(data,save_path,tf_size=10240):\n",
    "    '''\n",
    "        creates tf records:\n",
    "        args:\n",
    "            data        :   either the csv path or a dataframe\n",
    "            save_path   :   location to save tfrecords\n",
    "    '''\n",
    "    if type(data)==str:\n",
    "        data=pd.read_csv(data)\n",
    "        for col in eval_cols:\n",
    "            data[col]=data[col].progress_apply(lambda x: literal_eval(x))\n",
    "    \n",
    "    for idx in tqdm(range(0,len(data),tf_size)):\n",
    "        df        =   data.iloc[idx:idx+tf_size]  \n",
    "        rnum      =   idx//tf_size\n",
    "        toTfrecord(df,rnum,save_path)\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5acb98bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_dir=create_dir(save_dir,\"english\")\n",
    "rec_dir=create_dir(lang_dir,\"tfrecords\")\n",
    "data=os.path.join(lang_dir,\"data.csv\")\n",
    "createRecords(data,rec_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a71a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_dir=create_dir(save_dir,\"bangla\")\n",
    "rec_dir=create_dir(lang_dir,\"tfrecords\")\n",
    "data=os.path.join(lang_dir,\"data.csv\")\n",
    "createRecords(data,rec_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e9b475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# formulate robust scanner as backup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b66a0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification\n",
    "bn=os.path.join(save_dir,\"bangla\",\"data.csv\")\n",
    "en=os.path.join(save_dir,\"english\",\"data.csv\")\n",
    "bn=pd.read_csv(bn)\n",
    "en=pd.read_csv(en)\n",
    "bn=bn.sample(frac=1)\n",
    "bn.reset_index(inplace=True,drop=True)\n",
    "en=en.sample(frac=1)\n",
    "en.reset_index(inplace=True,drop=True)\n",
    "bn=bn[:100000]\n",
    "en=en[:100000]\n",
    "df=pd.concat([bn,en],ignore_index=True)\n",
    "df=df.sample(frac=1)\n",
    "df.reset_index(inplace=True,drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0beba43",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.label=df.filepath.progress_apply(lambda x: [1,0] if \"bangla\" in x else [0,1])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf5317a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_dir=create_dir(save_dir,\"classification\")\n",
    "createRecords(df,rec_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302acfa1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bangla",
   "language": "python",
   "name": "bangla"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
